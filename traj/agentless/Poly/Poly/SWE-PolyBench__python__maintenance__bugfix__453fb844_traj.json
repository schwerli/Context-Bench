{
    "instance_id": "SWE-PolyBench__python__maintenance__bugfix__453fb844",
    "original_id": "huggingface__transformers-13693",
    "1_model_selected_files": [
        "src/transformers/feature_extraction_sequence_utils.py",
        "src/transformers/models/wav2vec2/feature_extraction_wav2vec2.py",
        "src/transformers/feature_extraction_utils.py",
        "src/transformers/models/wav2vec2/processing_wav2vec2.py"
    ],
    "2_embedding_selected_files": [],
    "3_final_combined_files": [
        "src/transformers/feature_extraction_sequence_utils.py",
        "src/transformers/models/wav2vec2/feature_extraction_wav2vec2.py",
        "src/transformers/feature_extraction_utils.py"
    ],
    "4_related_elements": {
        "src/transformers/feature_extraction_sequence_utils.py": [
            "function: SequenceFeatureExtractor.pad\nfunction: SequenceFeatureExtractor._pad\nfunction: SequenceFeatureExtractor._truncate\nfunction: SequenceFeatureExtractor._get_padding_strategies"
        ],
        "src/transformers/feature_extraction_utils.py": [
            "function: BatchFeature.convert_to_tensors"
        ],
        "src/transformers/models/wav2vec2/feature_extraction_wav2vec2.py": [
            "function: Wav2Vec2FeatureExtractor.__call__\nfunction: Wav2Vec2FeatureExtractor.zero_mean_unit_var_norm"
        ]
    },
    "5_sampled_edit_locs_and_patches": [
        {
            "sample_index": 0,
            "edit_locs": {
                "src/transformers/feature_extraction_sequence_utils.py": [
                    "function: SequenceFeatureExtractor.pad\nline: 180\nline: 181\nline: 183\nline: 184"
                ],
                "src/transformers/feature_extraction_utils.py": [
                    "function: BatchFeature.convert_to_tensors\nline: 141\nline: 158"
                ],
                "src/transformers/models/wav2vec2/feature_extraction_wav2vec2.py": [
                    ""
                ]
            },
            "patches": [
                "diff --git a/src/transformers/feature_extraction_sequence_utils.py b/src/transformers/feature_extraction_sequence_utils.py\nindex e55e0fa..aeb9438 100644\n--- a/src/transformers/feature_extraction_sequence_utils.py\n+++ b/src/transformers/feature_extraction_sequence_utils.py\n@@ -203,6 +203,23 @@ class SequenceFeatureExtractor(FeatureExtractionMixin):\n                 pad_to_multiple_of=pad_to_multiple_of,\n                 return_attention_mask=return_attention_mask,\n             )\n+            # Ensure main model inputs are float32 for consistency with previous behavior\n+            main_input_name = self.model_input_names[0]\n+            if main_input_name in processed_features:\n+                main_value = processed_features[main_input_name]\n+                if isinstance(main_value, np.ndarray):\n+                    if np.issubdtype(main_value.dtype, np.floating):\n+                        processed_features[main_input_name] = main_value.astype(np.float32)\n+                elif isinstance(main_value, (list, tuple)):\n+                    new_list = []\n+                    for v in main_value:\n+                        if isinstance(v, np.ndarray) and np.issubdtype(v.dtype, np.floating):\n+                            new_list.append(v.astype(np.float32))\n+                        elif isinstance(v, (list, tuple)):\n+                            new_list.append(np.asarray(v, dtype=np.float32))\n+                        else:\n+                            new_list.append(v)\n+                    processed_features[main_input_name] = new_list\n             return BatchFeature(processed_features, tensor_type=return_tensors)\n \n         batch_size = len(required_input)\n@@ -242,6 +259,15 @@ class SequenceFeatureExtractor(FeatureExtractionMixin):\n                     batch_outputs[key] = []\n                 batch_outputs[key].append(value)\n \n+        # Ensure main model inputs are float32 for consistency with previous behavior\n+        main_input_name = self.model_input_names[0]\n+        if main_input_name in batch_outputs:\n+            batch_outputs[main_input_name] = [\n+                (v.astype(np.float32) if isinstance(v, np.ndarray) and np.issubdtype(v.dtype, np.floating)\n+                 else (np.asarray(v, dtype=np.float32) if isinstance(v, (list, tuple)) else v))\n+                for v in batch_outputs[main_input_name]\n+            ]\n+\n         return BatchFeature(batch_outputs, tensor_type=return_tensors)\n \n     def _pad(\n",
                "diff --git a/src/transformers/feature_extraction_sequence_utils.py b/src/transformers/feature_extraction_sequence_utils.py\nindex e55e0fa..85e6ca5 100644\n--- a/src/transformers/feature_extraction_sequence_utils.py\n+++ b/src/transformers/feature_extraction_sequence_utils.py\n@@ -183,6 +183,18 @@ class SequenceFeatureExtractor(FeatureExtractionMixin):\n             else:\n                 processed_features[key] = [to_numpy(v) for v in value]\n \n+            # Ensure the main model input (e.g., input_values for audio) is float32\n+            # to match previous behavior and model expectations.\n+            if key == self.model_input_names[0]:\n+                val = processed_features[key]\n+                if isinstance(val, list):\n+                    processed_features[key] = [\n+                        v.astype(np.float32) if isinstance(v, np.ndarray) and np.issubdtype(v.dtype, np.floating) else v\n+                        for v in val\n+                    ]\n+                elif isinstance(val, np.ndarray) and np.issubdtype(val.dtype, np.floating):\n+                    processed_features[key] = val.astype(np.float32)\n+\n         # Convert padding_strategy in PaddingStrategy\n         padding_strategy = self._get_padding_strategies(padding=padding, max_length=max_length)\n \n"
            ]
        },
        {
            "sample_index": 1,
            "edit_locs": {
                "src/transformers/models/wav2vec2/feature_extraction_wav2vec2.py": [
                    "function: Wav2Vec2FeatureExtractor.pad"
                ],
                "src/transformers/feature_extraction_sequence_utils.py": [
                    "function: SequenceFeatureExtractor.pad\nline: 180\nline: 181\nline: 182\nline: 183\nline: 184\nline: 185"
                ],
                "src/transformers/feature_extraction_utils.py": [
                    ""
                ]
            },
            "patches": [
                "diff --git a/src/transformers/feature_extraction_sequence_utils.py b/src/transformers/feature_extraction_sequence_utils.py\nindex e55e0fa..d45b285 100644\n--- a/src/transformers/feature_extraction_sequence_utils.py\n+++ b/src/transformers/feature_extraction_sequence_utils.py\n@@ -203,6 +203,18 @@ class SequenceFeatureExtractor(FeatureExtractionMixin):\n                 pad_to_multiple_of=pad_to_multiple_of,\n                 return_attention_mask=return_attention_mask,\n             )\n+            # Ensure float inputs are float32 when returning PyTorch tensors (backward compatibility)\n+            if return_tensors == \"pt\":\n+                main_input_name = self.model_input_names[0]\n+                if main_input_name in processed_features:\n+                    value = processed_features[main_input_name]\n+                    if isinstance(value, list):\n+                        processed_features[main_input_name] = [\n+                            v.astype(np.float32) if isinstance(v, np.ndarray) and np.issubdtype(v.dtype, np.floating) else v\n+                            for v in value\n+                        ]\n+                    elif isinstance(value, np.ndarray) and np.issubdtype(value.dtype, np.floating):\n+                        processed_features[main_input_name] = value.astype(np.float32)\n             return BatchFeature(processed_features, tensor_type=return_tensors)\n \n         batch_size = len(required_input)\n@@ -242,6 +254,16 @@ class SequenceFeatureExtractor(FeatureExtractionMixin):\n                     batch_outputs[key] = []\n                 batch_outputs[key].append(value)\n \n+        # Ensure float inputs are float32 when returning PyTorch tensors (backward compatibility)\n+        if return_tensors == \"pt\":\n+            main_input_name = self.model_input_names[0]\n+            if main_input_name in batch_outputs:\n+                values = batch_outputs[main_input_name]\n+                batch_outputs[main_input_name] = [\n+                    v.astype(np.float32) if isinstance(v, np.ndarray) and np.issubdtype(v.dtype, np.floating) else v\n+                    for v in values\n+                ]\n+\n         return BatchFeature(batch_outputs, tensor_type=return_tensors)\n \n     def _pad(\n",
                "diff --git a/src/transformers/feature_extraction_sequence_utils.py b/src/transformers/feature_extraction_sequence_utils.py\nindex e55e0fa..1efb811 100644\n--- a/src/transformers/feature_extraction_sequence_utils.py\n+++ b/src/transformers/feature_extraction_sequence_utils.py\n@@ -203,6 +203,17 @@ class SequenceFeatureExtractor(FeatureExtractionMixin):\n                 pad_to_multiple_of=pad_to_multiple_of,\n                 return_attention_mask=return_attention_mask,\n             )\n+            # Ensure PyTorch tensors for the main input are float32 for backward compatibility (e.g., Wav2Vec2).\n+            # Previous behavior returned torch.float32 even if inputs were np.float64.\n+            if return_tensors in (\"pt\", TensorType.PYTORCH) and self.model_input_names[0] in processed_features:\n+                val = processed_features[self.model_input_names[0]]\n+                if isinstance(val, list):\n+                    processed_features[self.model_input_names[0]] = [\n+                        v.astype(np.float32) if isinstance(v, np.ndarray) and np.issubdtype(v.dtype, np.floating) else v\n+                        for v in val\n+                    ]\n+                elif isinstance(val, np.ndarray) and np.issubdtype(val.dtype, np.floating):\n+                    processed_features[self.model_input_names[0]] = val.astype(np.float32)\n             return BatchFeature(processed_features, tensor_type=return_tensors)\n \n         batch_size = len(required_input)\n@@ -242,6 +253,12 @@ class SequenceFeatureExtractor(FeatureExtractionMixin):\n                     batch_outputs[key] = []\n                 batch_outputs[key].append(value)\n \n+        # Ensure PyTorch tensors for the main input are float32 for backward compatibility (e.g., Wav2Vec2).\n+        if return_tensors in (\"pt\", TensorType.PYTORCH) and self.model_input_names[0] in batch_outputs:\n+            batch_outputs[self.model_input_names[0]] = [\n+                v.astype(np.float32) if isinstance(v, np.ndarray) and np.issubdtype(v.dtype, np.floating) else v\n+                for v in batch_outputs[self.model_input_names[0]]\n+            ]\n         return BatchFeature(batch_outputs, tensor_type=return_tensors)\n \n     def _pad(\n"
            ]
        }
    ],
    "6_final_selected_patch": "diff --git a/src/transformers/feature_extraction_sequence_utils.py b/src/transformers/feature_extraction_sequence_utils.py\nindex e55e0fa..aeb9438 100644\n--- a/src/transformers/feature_extraction_sequence_utils.py\n+++ b/src/transformers/feature_extraction_sequence_utils.py\n@@ -203,6 +203,23 @@ class SequenceFeatureExtractor(FeatureExtractionMixin):\n                 pad_to_multiple_of=pad_to_multiple_of,\n                 return_attention_mask=return_attention_mask,\n             )\n+            # Ensure main model inputs are float32 for consistency with previous behavior\n+            main_input_name = self.model_input_names[0]\n+            if main_input_name in processed_features:\n+                main_value = processed_features[main_input_name]\n+                if isinstance(main_value, np.ndarray):\n+                    if np.issubdtype(main_value.dtype, np.floating):\n+                        processed_features[main_input_name] = main_value.astype(np.float32)\n+                elif isinstance(main_value, (list, tuple)):\n+                    new_list = []\n+                    for v in main_value:\n+                        if isinstance(v, np.ndarray) and np.issubdtype(v.dtype, np.floating):\n+                            new_list.append(v.astype(np.float32))\n+                        elif isinstance(v, (list, tuple)):\n+                            new_list.append(np.asarray(v, dtype=np.float32))\n+                        else:\n+                            new_list.append(v)\n+                    processed_features[main_input_name] = new_list\n             return BatchFeature(processed_features, tensor_type=return_tensors)\n \n         batch_size = len(required_input)\n@@ -242,6 +259,15 @@ class SequenceFeatureExtractor(FeatureExtractionMixin):\n                     batch_outputs[key] = []\n                 batch_outputs[key].append(value)\n \n+        # Ensure main model inputs are float32 for consistency with previous behavior\n+        main_input_name = self.model_input_names[0]\n+        if main_input_name in batch_outputs:\n+            batch_outputs[main_input_name] = [\n+                (v.astype(np.float32) if isinstance(v, np.ndarray) and np.issubdtype(v.dtype, np.floating)\n+                 else (np.asarray(v, dtype=np.float32) if isinstance(v, (list, tuple)) else v))\n+                for v in batch_outputs[main_input_name]\n+            ]\n+\n         return BatchFeature(batch_outputs, tensor_type=return_tensors)\n \n     def _pad(\n"
}