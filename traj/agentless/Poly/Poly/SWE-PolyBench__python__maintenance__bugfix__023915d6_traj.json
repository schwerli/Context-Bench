{
    "instance_id": "SWE-PolyBench__python__maintenance__bugfix__023915d6",
    "original_id": "huggingface__transformers-27663",
    "1_model_selected_files": [
        "src/transformers/image_transforms.py",
        "src/transformers/models/yolos/image_processing_yolos.py",
        "src/transformers/image_processing_utils.py",
        "src/transformers/models/yolos/feature_extraction_yolos.py",
        "src/transformers/image_utils.py"
    ],
    "2_embedding_selected_files": [],
    "3_final_combined_files": [
        "src/transformers/image_transforms.py",
        "src/transformers/models/yolos/image_processing_yolos.py",
        "src/transformers/image_processing_utils.py"
    ],
    "4_related_elements": {
        "src/transformers/models/yolos/image_processing_yolos.py": [
            "function: get_size_with_aspect_ratio\nfunction: get_resize_output_image_size\nfunction: YolosImageProcessor.resize\nfunction: YolosImageProcessor.preprocess"
        ],
        "src/transformers/image_transforms.py": [
            "function: get_resize_output_image_size\nfunction: resize"
        ],
        "src/transformers/image_processing_utils.py": [
            "variable: VALID_SIZE_DICT_KEYS\nfunction: is_valid_size_dict\nfunction: convert_to_size_dict\nfunction: get_size_dict"
        ]
    },
    "5_sampled_edit_locs_and_patches": [
        {
            "sample_index": 0,
            "edit_locs": {
                "src/transformers/models/yolos/image_processing_yolos.py": [
                    "function: get_size_with_aspect_ratio\nline: 120"
                ],
                "src/transformers/image_transforms.py": [
                    ""
                ],
                "src/transformers/image_processing_utils.py": [
                    ""
                ]
            },
            "patches": [
                "diff --git a/src/transformers/models/yolos/image_processing_yolos.py b/src/transformers/models/yolos/image_processing_yolos.py\nindex 40e7dd7..d5e3a9e 100644\n--- a/src/transformers/models/yolos/image_processing_yolos.py\n+++ b/src/transformers/models/yolos/image_processing_yolos.py\n@@ -117,10 +117,13 @@ def get_size_with_aspect_ratio(image_size, size, max_size=None) -> Tuple[int, in\n         min_original_size = float(min((height, width)))\n         max_original_size = float(max((height, width)))\n         if max_original_size / min_original_size * size > max_size:\n-            size = int(round(max_size * min_original_size / max_original_size))\n+            # Use flooring to ensure the longest edge does not exceed `max_size`\n+            size = int(max_size * min_original_size / max_original_size)\n \n-    if (height <= width and height == size) or (width <= height and width == size):\n-        return height, width\n+    # Only return early when there is no `max_size` constraint.\n+    if ((height <= width and height == size) or (width <= height and width == size)):\n+        if max_size is None:\n+            return height, width\n \n     if width < height:\n         ow = size\n",
                "diff --git a/src/transformers/models/yolos/image_processing_yolos.py b/src/transformers/models/yolos/image_processing_yolos.py\nindex 40e7dd7..4fa0a7f 100644\n--- a/src/transformers/models/yolos/image_processing_yolos.py\n+++ b/src/transformers/models/yolos/image_processing_yolos.py\n@@ -117,7 +117,8 @@ def get_size_with_aspect_ratio(image_size, size, max_size=None) -> Tuple[int, in\n         min_original_size = float(min((height, width)))\n         max_original_size = float(max((height, width)))\n         if max_original_size / min_original_size * size > max_size:\n-            size = int(round(max_size * min_original_size / max_original_size))\n+            # Floor the adjusted size to guarantee the longest edge does not exceed max_size\n+            size = int(max_size * min_original_size / max_original_size)\n \n     if (height <= width and height == size) or (width <= height and width == size):\n         return height, width\n"
            ]
        },
        {
            "sample_index": 1,
            "edit_locs": {
                "src/transformers/models/yolos/image_processing_yolos.py": [
                    "function: get_size_with_aspect_ratio\nline: 120"
                ],
                "src/transformers/image_transforms.py": [
                    ""
                ],
                "src/transformers/image_processing_utils.py": [
                    ""
                ]
            },
            "patches": [
                "diff --git a/src/transformers/models/yolos/image_processing_yolos.py b/src/transformers/models/yolos/image_processing_yolos.py\nindex 40e7dd7..8cb7015 100644\n--- a/src/transformers/models/yolos/image_processing_yolos.py\n+++ b/src/transformers/models/yolos/image_processing_yolos.py\n@@ -117,7 +117,9 @@ def get_size_with_aspect_ratio(image_size, size, max_size=None) -> Tuple[int, in\n         min_original_size = float(min((height, width)))\n         max_original_size = float(max((height, width)))\n         if max_original_size / min_original_size * size > max_size:\n-            size = int(round(max_size * min_original_size / max_original_size))\n+            # Use floor to guarantee that the longest edge does not exceed max_size.\n+            # Also ensure the computed size is at least 1 to avoid invalid resize dims.\n+            size = max(1, int(np.floor(max_size * min_original_size / max_original_size)))\n \n     if (height <= width and height == size) or (width <= height and width == size):\n         return height, width\n",
                "diff --git a/src/transformers/models/yolos/image_processing_yolos.py b/src/transformers/models/yolos/image_processing_yolos.py\nindex 40e7dd7..0847196 100644\n--- a/src/transformers/models/yolos/image_processing_yolos.py\n+++ b/src/transformers/models/yolos/image_processing_yolos.py\n@@ -117,7 +117,7 @@ def get_size_with_aspect_ratio(image_size, size, max_size=None) -> Tuple[int, in\n         min_original_size = float(min((height, width)))\n         max_original_size = float(max((height, width)))\n         if max_original_size / min_original_size * size > max_size:\n-            size = int(round(max_size * min_original_size / max_original_size))\n+            size = int(np.floor(max_size * min_original_size / max_original_size))\n \n     if (height <= width and height == size) or (width <= height and width == size):\n         return height, width\n"
            ]
        }
    ],
    "6_final_selected_patch": "diff --git a/src/transformers/models/yolos/image_processing_yolos.py b/src/transformers/models/yolos/image_processing_yolos.py\nindex 40e7dd7..d5e3a9e 100644\n--- a/src/transformers/models/yolos/image_processing_yolos.py\n+++ b/src/transformers/models/yolos/image_processing_yolos.py\n@@ -117,10 +117,13 @@ def get_size_with_aspect_ratio(image_size, size, max_size=None) -> Tuple[int, in\n         min_original_size = float(min((height, width)))\n         max_original_size = float(max((height, width)))\n         if max_original_size / min_original_size * size > max_size:\n-            size = int(round(max_size * min_original_size / max_original_size))\n+            # Use flooring to ensure the longest edge does not exceed `max_size`\n+            size = int(max_size * min_original_size / max_original_size)\n \n-    if (height <= width and height == size) or (width <= height and width == size):\n-        return height, width\n+    # Only return early when there is no `max_size` constraint.\n+    if ((height <= width and height == size) or (width <= height and width == size)):\n+        if max_size is None:\n+            return height, width\n \n     if width < height:\n         ow = size\n"
}