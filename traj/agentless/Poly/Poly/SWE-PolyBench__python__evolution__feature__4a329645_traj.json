{
    "instance_id": "SWE-PolyBench__python__evolution__feature__4a329645",
    "original_id": "huggingface__transformers-15795",
    "1_model_selected_files": [
        "src/transformers/hf_argparser.py"
    ],
    "2_embedding_selected_files": [],
    "3_final_combined_files": [
        "src/transformers/hf_argparser.py"
    ],
    "4_related_elements": {
        "src/transformers/hf_argparser.py": [
            "function: HfArgumentParser.__init__\nfunction: HfArgumentParser._add_dataclass_arguments\nfunction: HfArgumentParser.parse_args_into_dataclasses\nfunction: HfArgumentParser.parse_json_file\nfunction: HfArgumentParser.parse_dict"
        ]
    },
    "5_sampled_edit_locs_and_patches": [
        {
            "sample_index": 0,
            "edit_locs": {
                "src/transformers/hf_argparser.py": [
                    "function: HfArgumentParser._add_dataclass_arguments\nline: 85\nline: 86\nline: 87\nline: 88\nline: 89\nline: 90"
                ]
            },
            "patches": [
                "diff --git a/src/transformers/hf_argparser.py b/src/transformers/hf_argparser.py\nindex 4d9ec56..dfc1c32 100644\n--- a/src/transformers/hf_argparser.py\n+++ b/src/transformers/hf_argparser.py\n@@ -83,11 +83,22 @@ class HfArgumentParser(ArgumentParser):\n             # field.metadata is not used at all by Data Classes,\n             # it is provided as a third-party extension mechanism.\n             if isinstance(field.type, str):\n-                raise ImportError(\n-                    \"This implementation is not compatible with Postponed Evaluation of Annotations (PEP 563), \"\n-                    \"which can be opted in from Python 3.7 with `from __future__ import annotations`. \"\n-                    \"We will add compatibility when Python 3.9 is released.\"\n-                )\n+                # Resolve postponed annotations (PEP 563) to actual types\n+                try:\n+                    typing_mod = __import__(\"typing\")\n+                    # Resolve using typing.get_type_hints which handles ForwardRef and strings\n+                    type_hints = typing_mod.get_type_hints(dtype)\n+                    resolved = type_hints.get(field.name, None)\n+                    if resolved is None:\n+                        # Fallback: evaluate the annotation in the dataclass module's globals\n+                        module = __import__(dtype.__module__, fromlist=[\"*\"])\n+                        resolved = eval(field.type, module.__dict__)\n+                    field.type = resolved\n+                except Exception as e:\n+                    raise ImportError(\n+                        \"Failed to resolve postponed annotations (PEP 563) for dataclass field \"\n+                        f\"{field.name!r} in {dtype}. Please ensure all types are importable.\"\n+                    ) from e\n             typestring = str(field.type)\n             for prim_type in (int, float, str):\n                 for collection in (List,):\n",
                "diff --git a/src/transformers/hf_argparser.py b/src/transformers/hf_argparser.py\nindex 4d9ec56..02bfab0 100644\n--- a/src/transformers/hf_argparser.py\n+++ b/src/transformers/hf_argparser.py\n@@ -75,6 +75,13 @@ class HfArgumentParser(ArgumentParser):\n             parser = self.add_argument_group(dtype._argument_group_name)\n         else:\n             parser = self\n+        # Resolve type hints to support postponed evaluation of annotations (PEP 563 / `from __future__ import annotations`)\n+        try:\n+            from typing import get_type_hints\n+            type_hints = get_type_hints(dtype)\n+        except Exception:\n+            # If we cannot resolve type hints, we'll fallback to best-effort eval per field later\n+            type_hints = {}\n         for field in dataclasses.fields(dtype):\n             if not field.init:\n                 continue\n@@ -83,11 +90,24 @@ class HfArgumentParser(ArgumentParser):\n             # field.metadata is not used at all by Data Classes,\n             # it is provided as a third-party extension mechanism.\n             if isinstance(field.type, str):\n-                raise ImportError(\n-                    \"This implementation is not compatible with Postponed Evaluation of Annotations (PEP 563), \"\n-                    \"which can be opted in from Python 3.7 with `from __future__ import annotations`. \"\n-                    \"We will add compatibility when Python 3.9 is released.\"\n-                )\n+                # Resolve string annotations (PEP 563 / __future__ annotations) to actual types\n+                resolved = type_hints.get(field.name, None)\n+                if resolved is not None:\n+                    field.type = resolved\n+                else:\n+                    # Fallback: try to evaluate the annotation string in the module's namespace (with typing)\n+                    try:\n+                        import sys\n+                        import typing as _typing\n+                        module_globals = sys.modules[dtype.__module__].__dict__\n+                        # Merge typing names to help resolve typing constructs like Optional, List, etc.\n+                        eval_globals = {**module_globals, **_typing.__dict__}\n+                        field.type = eval(field.type, eval_globals)\n+                    except Exception:\n+                        raise ImportError(\n+                            f\"Could not resolve postponed annotation for field '{field.name}'. \"\n+                            \"Please ensure annotations are importable and valid.\"\n+                        )\n             typestring = str(field.type)\n             for prim_type in (int, float, str):\n                 for collection in (List,):\n"
            ]
        },
        {
            "sample_index": 1,
            "edit_locs": {
                "src/transformers/hf_argparser.py": [
                    "function: HfArgumentParser._add_dataclass_arguments\nline: 85\nline: 86\nline: 87\nline: 88\nline: 89\nline: 90"
                ]
            },
            "patches": [
                "diff --git a/src/transformers/hf_argparser.py b/src/transformers/hf_argparser.py\nindex 4d9ec56..041d739 100644\n--- a/src/transformers/hf_argparser.py\n+++ b/src/transformers/hf_argparser.py\n@@ -75,6 +75,12 @@ class HfArgumentParser(ArgumentParser):\n             parser = self.add_argument_group(dtype._argument_group_name)\n         else:\n             parser = self\n+        # Resolve postponed evaluation of annotations (PEP 563 / future annotations)\n+        try:\n+            from typing import get_type_hints\n+            type_hints = get_type_hints(dtype)\n+        except Exception:\n+            type_hints = {}\n         for field in dataclasses.fields(dtype):\n             if not field.init:\n                 continue\n@@ -82,44 +88,40 @@ class HfArgumentParser(ArgumentParser):\n             kwargs = field.metadata.copy()\n             # field.metadata is not used at all by Data Classes,\n             # it is provided as a third-party extension mechanism.\n-            if isinstance(field.type, str):\n-                raise ImportError(\n-                    \"This implementation is not compatible with Postponed Evaluation of Annotations (PEP 563), \"\n-                    \"which can be opted in from Python 3.7 with `from __future__ import annotations`. \"\n-                    \"We will add compatibility when Python 3.9 is released.\"\n-                )\n-            typestring = str(field.type)\n+            field_type = type_hints.get(field.name, field.type)\n+\n+            typestring = str(field_type)\n             for prim_type in (int, float, str):\n                 for collection in (List,):\n                     if (\n                         typestring == f\"typing.Union[{collection[prim_type]}, NoneType]\"\n                         or typestring == f\"typing.Optional[{collection[prim_type]}]\"\n                     ):\n-                        field.type = collection[prim_type]\n+                        field_type = collection[prim_type]\n                 if (\n                     typestring == f\"typing.Union[{prim_type.__name__}, NoneType]\"\n                     or typestring == f\"typing.Optional[{prim_type.__name__}]\"\n                 ):\n-                    field.type = prim_type\n+                    field_type = prim_type\n \n             # A variable to store kwargs for a boolean field, if needed\n             # so that we can init a `no_*` complement argument (see below)\n             bool_kwargs = {}\n-            if isinstance(field.type, type) and issubclass(field.type, Enum):\n-                kwargs[\"choices\"] = [x.value for x in field.type]\n+            if isinstance(field_type, type) and issubclass(field_type, Enum):\n+                kwargs[\"choices\"] = [x.value for x in field_type]\n                 kwargs[\"type\"] = type(kwargs[\"choices\"][0])\n                 if field.default is not dataclasses.MISSING:\n                     kwargs[\"default\"] = field.default\n                 else:\n                     kwargs[\"required\"] = True\n-            elif field.type is bool or field.type == Optional[bool]:\n+            elif field_type is bool or field_type == Optional[bool]:\n                 # Copy the currect kwargs to use to instantiate a `no_*` complement argument below.\n                 # We do not init it here because the `no_*` alternative must be instantiated after the real argument\n                 bool_kwargs = copy(kwargs)\n \n                 # Hack because type=bool in argparse does not behave as we want.\n                 kwargs[\"type\"] = string_to_bool\n-                if field.type is bool or (field.default is not None and field.default is not dataclasses.MISSING):\n+                if field_type is bool or (field.default is not None and field.default is not dataclasses.MISSING):\n                     # Default value is False if we have no default when of type bool.\n                     default = False if field.default is dataclasses.MISSING else field.default\n                     # This is the value that will get picked if we don't include --field_name in any way\n@@ -129,19 +131,19 @@ class HfArgumentParser(ArgumentParser):\n                     # This is the value that will get picked if we do --field_name (without value)\n                     kwargs[\"const\"] = True\n             elif (\n-                hasattr(field.type, \"__origin__\")\n-                and re.search(r\"^(typing\\.List|list)\\[(.*)\\]$\", str(field.type)) is not None\n+                hasattr(field_type, \"__origin__\")\n+                and re.search(r\"^(typing\\.List|list)\\[(.*)\\]$\", str(field_type)) is not None\n             ):\n                 kwargs[\"nargs\"] = \"+\"\n-                kwargs[\"type\"] = field.type.__args__[0]\n-                if not all(x == kwargs[\"type\"] for x in field.type.__args__):\n+                kwargs[\"type\"] = field_type.__args__[0]\n+                if not all(x == kwargs[\"type\"] for x in field_type.__args__):\n                     raise ValueError(f\"{field.name} cannot be a List of mixed types\")\n                 if field.default_factory is not dataclasses.MISSING:\n                     kwargs[\"default\"] = field.default_factory()\n                 elif field.default is dataclasses.MISSING:\n                     kwargs[\"required\"] = True\n             else:\n-                kwargs[\"type\"] = field.type\n+                kwargs[\"type\"] = field_type\n                 if field.default is not dataclasses.MISSING:\n                     kwargs[\"default\"] = field.default\n                 elif field.default_factory is not dataclasses.MISSING:\n@@ -154,7 +156,7 @@ class HfArgumentParser(ArgumentParser):\n             # Order is important for arguments with the same destination!\n             # We use a copy of earlier kwargs because the original kwargs have changed a lot before reaching down\n             # here and we do not need those changes/additional keys.\n-            if field.default is True and (field.type is bool or field.type == Optional[bool]):\n+            if field.default is True and (field_type is bool or field_type == Optional[bool]):\n                 bool_kwargs[\"default\"] = False\n                 parser.add_argument(f\"--no_{field.name}\", action=\"store_false\", dest=field.name, **bool_kwargs)\n \n",
                "diff --git a/src/transformers/hf_argparser.py b/src/transformers/hf_argparser.py\nindex 4d9ec56..c5b5d63 100644\n--- a/src/transformers/hf_argparser.py\n+++ b/src/transformers/hf_argparser.py\n@@ -75,6 +75,13 @@ class HfArgumentParser(ArgumentParser):\n             parser = self.add_argument_group(dtype._argument_group_name)\n         else:\n             parser = self\n+        from typing import get_type_hints\n+        try:\n+            type_hints = get_type_hints(dtype)\n+        except Exception:\n+            # Fallback if some annotations cannot be resolved\n+            type_hints = getattr(dtype, \"__annotations__\", {})\n+\n         for field in dataclasses.fields(dtype):\n             if not field.init:\n                 continue\n@@ -82,44 +89,42 @@ class HfArgumentParser(ArgumentParser):\n             kwargs = field.metadata.copy()\n             # field.metadata is not used at all by Data Classes,\n             # it is provided as a third-party extension mechanism.\n-            if isinstance(field.type, str):\n-                raise ImportError(\n-                    \"This implementation is not compatible with Postponed Evaluation of Annotations (PEP 563), \"\n-                    \"which can be opted in from Python 3.7 with `from __future__ import annotations`. \"\n-                    \"We will add compatibility when Python 3.9 is released.\"\n-                )\n-            typestring = str(field.type)\n+\n+            # Determine the real type, compatible with postponed evaluation of annotations (PEP 563)\n+            field_type = type_hints.get(field.name, field.type)\n+\n+            typestring = str(field_type)\n             for prim_type in (int, float, str):\n                 for collection in (List,):\n                     if (\n                         typestring == f\"typing.Union[{collection[prim_type]}, NoneType]\"\n                         or typestring == f\"typing.Optional[{collection[prim_type]}]\"\n                     ):\n-                        field.type = collection[prim_type]\n+                        field_type = collection[prim_type]\n                 if (\n                     typestring == f\"typing.Union[{prim_type.__name__}, NoneType]\"\n                     or typestring == f\"typing.Optional[{prim_type.__name__}]\"\n                 ):\n-                    field.type = prim_type\n+                    field_type = prim_type\n \n             # A variable to store kwargs for a boolean field, if needed\n             # so that we can init a `no_*` complement argument (see below)\n             bool_kwargs = {}\n-            if isinstance(field.type, type) and issubclass(field.type, Enum):\n-                kwargs[\"choices\"] = [x.value for x in field.type]\n+            if isinstance(field_type, type) and issubclass(field_type, Enum):\n+                kwargs[\"choices\"] = [x.value for x in field_type]\n                 kwargs[\"type\"] = type(kwargs[\"choices\"][0])\n                 if field.default is not dataclasses.MISSING:\n                     kwargs[\"default\"] = field.default\n                 else:\n                     kwargs[\"required\"] = True\n-            elif field.type is bool or field.type == Optional[bool]:\n-                # Copy the currect kwargs to use to instantiate a `no_*` complement argument below.\n+            elif field_type is bool or field_type == Optional[bool]:\n+                # Copy the current kwargs to use to instantiate a `no_*` complement argument below.\n                 # We do not init it here because the `no_*` alternative must be instantiated after the real argument\n                 bool_kwargs = copy(kwargs)\n \n                 # Hack because type=bool in argparse does not behave as we want.\n                 kwargs[\"type\"] = string_to_bool\n-                if field.type is bool or (field.default is not None and field.default is not dataclasses.MISSING):\n+                if field_type is bool or (field.default is not None and field.default is not dataclasses.MISSING):\n                     # Default value is False if we have no default when of type bool.\n                     default = False if field.default is dataclasses.MISSING else field.default\n                     # This is the value that will get picked if we don't include --field_name in any way\n@@ -129,19 +134,20 @@ class HfArgumentParser(ArgumentParser):\n                     # This is the value that will get picked if we do --field_name (without value)\n                     kwargs[\"const\"] = True\n             elif (\n-                hasattr(field.type, \"__origin__\")\n-                and re.search(r\"^(typing\\.List|list)\\[(.*)\\]$\", str(field.type)) is not None\n+                hasattr(field_type, \"__origin__\")\n+                and re.search(r\"^(typing\\.List|list)\\[(.*)\\]$\", str(field_type)) is not None\n             ):\n                 kwargs[\"nargs\"] = \"+\"\n-                kwargs[\"type\"] = field.type.__args__[0]\n-                if not all(x == kwargs[\"type\"] for x in field.type.__args__):\n+                elem_type = field_type.__args__[0]\n+                kwargs[\"type\"] = elem_type\n+                if not all(x == kwargs[\"type\"] for x in field_type.__args__):\n                     raise ValueError(f\"{field.name} cannot be a List of mixed types\")\n                 if field.default_factory is not dataclasses.MISSING:\n                     kwargs[\"default\"] = field.default_factory()\n                 elif field.default is dataclasses.MISSING:\n                     kwargs[\"required\"] = True\n             else:\n-                kwargs[\"type\"] = field.type\n+                kwargs[\"type\"] = field_type\n                 if field.default is not dataclasses.MISSING:\n                     kwargs[\"default\"] = field.default\n                 elif field.default_factory is not dataclasses.MISSING:\n@@ -154,7 +160,7 @@ class HfArgumentParser(ArgumentParser):\n             # Order is important for arguments with the same destination!\n             # We use a copy of earlier kwargs because the original kwargs have changed a lot before reaching down\n             # here and we do not need those changes/additional keys.\n-            if field.default is True and (field.type is bool or field.type == Optional[bool]):\n+            if field.default is True and (field_type is bool or field_type == Optional[bool]):\n                 bool_kwargs[\"default\"] = False\n                 parser.add_argument(f\"--no_{field.name}\", action=\"store_false\", dest=field.name, **bool_kwargs)\n \n"
            ]
        }
    ],
    "6_final_selected_patch": "diff --git a/src/transformers/hf_argparser.py b/src/transformers/hf_argparser.py\nindex 4d9ec56..dfc1c32 100644\n--- a/src/transformers/hf_argparser.py\n+++ b/src/transformers/hf_argparser.py\n@@ -83,11 +83,22 @@ class HfArgumentParser(ArgumentParser):\n             # field.metadata is not used at all by Data Classes,\n             # it is provided as a third-party extension mechanism.\n             if isinstance(field.type, str):\n-                raise ImportError(\n-                    \"This implementation is not compatible with Postponed Evaluation of Annotations (PEP 563), \"\n-                    \"which can be opted in from Python 3.7 with `from __future__ import annotations`. \"\n-                    \"We will add compatibility when Python 3.9 is released.\"\n-                )\n+                # Resolve postponed annotations (PEP 563) to actual types\n+                try:\n+                    typing_mod = __import__(\"typing\")\n+                    # Resolve using typing.get_type_hints which handles ForwardRef and strings\n+                    type_hints = typing_mod.get_type_hints(dtype)\n+                    resolved = type_hints.get(field.name, None)\n+                    if resolved is None:\n+                        # Fallback: evaluate the annotation in the dataclass module's globals\n+                        module = __import__(dtype.__module__, fromlist=[\"*\"])\n+                        resolved = eval(field.type, module.__dict__)\n+                    field.type = resolved\n+                except Exception as e:\n+                    raise ImportError(\n+                        \"Failed to resolve postponed annotations (PEP 563) for dataclass field \"\n+                        f\"{field.name!r} in {dtype}. Please ensure all types are importable.\"\n+                    ) from e\n             typestring = str(field.type)\n             for prim_type in (int, float, str):\n                 for collection in (List,):\n"
}