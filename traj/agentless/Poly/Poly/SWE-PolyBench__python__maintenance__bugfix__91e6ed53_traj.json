{
    "instance_id": "SWE-PolyBench__python__maintenance__bugfix__91e6ed53",
    "original_id": "huggingface__transformers-21969",
    "1_model_selected_files": [
        "src/transformers/models/mask2former/image_processing_mask2former.py",
        "src/transformers/image_transforms.py",
        "src/transformers/image_utils.py",
        "src/transformers/image_processing_utils.py",
        "src/transformers/models/auto/image_processing_auto.py"
    ],
    "2_embedding_selected_files": [],
    "3_final_combined_files": [
        "src/transformers/models/mask2former/image_processing_mask2former.py",
        "src/transformers/image_transforms.py",
        "src/transformers/image_utils.py"
    ],
    "4_related_elements": {
        "src/transformers/models/mask2former/image_processing_mask2former.py": [
            "class: Mask2FormerImageProcessor\nfunction: get_mask2former_resize_output_image_size"
        ],
        "src/transformers/image_transforms.py": [
            "function: to_channel_dimension_format\nfunction: to_pil_image\nfunction: resize\nfunction: get_resize_output_image_size\nfunction: rescale\nfunction: normalize\nfunction: convert_to_rgb"
        ],
        "src/transformers/image_utils.py": [
            "class: ChannelDimension\nfunction: to_numpy_array\nfunction: infer_channel_dimension_format\nfunction: get_channel_dimension_axis\nfunction: get_image_size\nfunction: make_list_of_images\nclass: ImageFeatureExtractionMixin"
        ]
    },
    "5_sampled_edit_locs_and_patches": [
        {
            "sample_index": 0,
            "edit_locs": {
                "src/transformers/models/mask2former/image_processing_mask2former.py": [
                    "function: Mask2FormerImageProcessor._preprocess"
                ],
                "src/transformers/image_transforms.py": [
                    "function: to_pil_image\nfunction: resize"
                ],
                "src/transformers/image_utils.py": [
                    ""
                ]
            },
            "patches": [
                "diff --git a/src/transformers/image_transforms.py b/src/transformers/image_transforms.py\nindex fb09028..4d19ef6 100644\n--- a/src/transformers/image_transforms.py\n+++ b/src/transformers/image_transforms.py\n@@ -156,9 +156,22 @@ def to_pil_image(\n     image = np.squeeze(image, axis=-1) if image.shape[-1] == 1 else image\n \n     # PIL.Image can only store uint8 values, so we rescale the image to be between 0 and 255 if needed.\n-    do_rescale = isinstance(image.flat[0], (float, np.float32, np.float64)) if do_rescale is None else do_rescale\n+    if do_rescale is None:\n+        # Only rescale float arrays that are in [0, 1]. If they are already in [0, 255], don't rescale.\n+        if np.issubdtype(image.dtype, np.floating):\n+            # Guard against NaNs/Infs by using finite values for range check\n+            finite_image = image[np.isfinite(image)]\n+            if finite_image.size == 0:\n+                # Fallback to rescaling to avoid producing an all-zero image\n+                do_rescale = True\n+            else:\n+                min_val = float(finite_image.min())\n+                max_val = float(finite_image.max())\n+                do_rescale = (min_val >= 0.0) and (max_val <= 1.0)\n+        else:\n+            do_rescale = False\n     if do_rescale:\n-        image = rescale(image, 255)\n+        image = rescale(image, 255.0)\n     image = image.astype(np.uint8)\n     return PIL.Image.fromarray(image)\n \n",
                "diff --git a/src/transformers/image_transforms.py b/src/transformers/image_transforms.py\nindex fb09028..6fdff0d 100644\n--- a/src/transformers/image_transforms.py\n+++ b/src/transformers/image_transforms.py\n@@ -155,11 +155,20 @@ def to_pil_image(\n     # If there is a single channel, we squeeze it, as otherwise PIL can't handle it.\n     image = np.squeeze(image, axis=-1) if image.shape[-1] == 1 else image\n \n-    # PIL.Image can only store uint8 values, so we rescale the image to be between 0 and 255 if needed.\n-    do_rescale = isinstance(image.flat[0], (float, np.float32, np.float64)) if do_rescale is None else do_rescale\n+    # PIL.Image can only store uint8 values. Determine whether to rescale:\n+    # only rescale floating point images that appear to be in [0, 1].\n+    if do_rescale is None:\n+        is_float = np.issubdtype(image.dtype, np.floating)\n+        if is_float:\n+            img_min = float(np.min(image))\n+            img_max = float(np.max(image))\n+            do_rescale = 0.0 <= img_min and img_max <= 1.0\n+        else:\n+            do_rescale = False\n     if do_rescale:\n-        image = rescale(image, 255)\n-    image = image.astype(np.uint8)\n+        image = rescale(image, 255.0)\n+    # Avoid wrap-around on casting by clipping to the valid uint8 range\n+    image = np.clip(image, 0, 255).astype(np.uint8)\n     return PIL.Image.fromarray(image)\n \n \n"
            ]
        },
        {
            "sample_index": 1,
            "edit_locs": {
                "src/transformers/image_transforms.py": [
                    "function: to_pil_image\nfunction: resize"
                ],
                "src/transformers/models/mask2former/image_processing_mask2former.py": [
                    ""
                ],
                "src/transformers/image_utils.py": [
                    ""
                ]
            },
            "patches": [
                "diff --git a/src/transformers/image_transforms.py b/src/transformers/image_transforms.py\nindex fb09028..b8abe2c 100644\n--- a/src/transformers/image_transforms.py\n+++ b/src/transformers/image_transforms.py\n@@ -156,7 +156,15 @@ def to_pil_image(\n     image = np.squeeze(image, axis=-1) if image.shape[-1] == 1 else image\n \n     # PIL.Image can only store uint8 values, so we rescale the image to be between 0 and 255 if needed.\n-    do_rescale = isinstance(image.flat[0], (float, np.float32, np.float64)) if do_rescale is None else do_rescale\n+    if do_rescale is None:\n+        # Only rescale floating point images that appear to be in [0, 1]\n+        if isinstance(image.flat[0], (float, np.floating)):\n+            # Infer whether rescaling is necessary based on dynamic range\n+            img_min = float(np.nanmin(image))\n+            img_max = float(np.nanmax(image))\n+            do_rescale = img_min >= 0.0 and img_max <= 1.0\n+        else:\n+            do_rescale = False\n     if do_rescale:\n         image = rescale(image, 255)\n     image = image.astype(np.uint8)\n",
                "diff --git a/src/transformers/image_transforms.py b/src/transformers/image_transforms.py\nindex fb09028..1c3990c 100644\n--- a/src/transformers/image_transforms.py\n+++ b/src/transformers/image_transforms.py\n@@ -156,7 +156,20 @@ def to_pil_image(\n     image = np.squeeze(image, axis=-1) if image.shape[-1] == 1 else image\n \n     # PIL.Image can only store uint8 values, so we rescale the image to be between 0 and 255 if needed.\n-    do_rescale = isinstance(image.flat[0], (float, np.float32, np.float64)) if do_rescale is None else do_rescale\n+    if do_rescale is None:\n+        # Only rescale floating point images that are already in [0, 1].\n+        # If the image is floating point but in [0, 255], we should not multiply by 255 again.\n+        if np.issubdtype(image.dtype, np.floating):\n+            finite_mask = np.isfinite(image)\n+            if finite_mask.any():\n+                img_min = float(image[finite_mask].min())\n+                img_max = float(image[finite_mask].max())\n+                do_rescale = 0.0 <= img_min and img_max <= 1.0\n+            else:\n+                # If values are non-finite, default to rescaling to avoid unexpected behavior\n+                do_rescale = True\n+        else:\n+            do_rescale = False\n     if do_rescale:\n         image = rescale(image, 255)\n     image = image.astype(np.uint8)\n"
            ]
        }
    ],
    "6_final_selected_patch": "diff --git a/src/transformers/image_transforms.py b/src/transformers/image_transforms.py\nindex fb09028..4d19ef6 100644\n--- a/src/transformers/image_transforms.py\n+++ b/src/transformers/image_transforms.py\n@@ -156,9 +156,22 @@ def to_pil_image(\n     image = np.squeeze(image, axis=-1) if image.shape[-1] == 1 else image\n \n     # PIL.Image can only store uint8 values, so we rescale the image to be between 0 and 255 if needed.\n-    do_rescale = isinstance(image.flat[0], (float, np.float32, np.float64)) if do_rescale is None else do_rescale\n+    if do_rescale is None:\n+        # Only rescale float arrays that are in [0, 1]. If they are already in [0, 255], don't rescale.\n+        if np.issubdtype(image.dtype, np.floating):\n+            # Guard against NaNs/Infs by using finite values for range check\n+            finite_image = image[np.isfinite(image)]\n+            if finite_image.size == 0:\n+                # Fallback to rescaling to avoid producing an all-zero image\n+                do_rescale = True\n+            else:\n+                min_val = float(finite_image.min())\n+                max_val = float(finite_image.max())\n+                do_rescale = (min_val >= 0.0) and (max_val <= 1.0)\n+        else:\n+            do_rescale = False\n     if do_rescale:\n-        image = rescale(image, 255)\n+        image = rescale(image, 255.0)\n     image = image.astype(np.uint8)\n     return PIL.Image.fromarray(image)\n \n"
}