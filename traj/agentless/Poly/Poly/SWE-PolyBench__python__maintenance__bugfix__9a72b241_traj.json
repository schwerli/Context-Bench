{
    "instance_id": "SWE-PolyBench__python__maintenance__bugfix__9a72b241",
    "original_id": "huggingface__transformers-5122",
    "1_model_selected_files": [
        "src/transformers/data/data_collator.py"
    ],
    "2_embedding_selected_files": [
        "examples/text-classification/run_pl_glue.py",
        "examples/text-classification/run_glue.py",
        "examples/text-classification/run_tf_glue.py",
        "src/transformers/data/processors/glue.py",
        "src/transformers/data/__init__.py",
        "examples/bertology/run_bertology.py",
        "src/transformers/data/processors/__init__.py",
        "examples/distillation/run_squad_w_distillation.py",
        "src/transformers/__init__.py",
        "examples/text-generation/pplm/run_pplm_discrim_train.py",
        "src/transformers/data/datasets/__init__.py",
        "src/transformers/data/metrics/__init__.py",
        "src/transformers/modeling_tf_auto.py",
        "src/transformers/modeling_gpt2.py",
        "src/transformers/convert_pytorch_checkpoint_to_tf2.py",
        "src/transformers/data/datasets/glue.py",
        "src/transformers/pipelines.py",
        "examples/question-answering/run_tf_squad.py",
        "examples/token-classification/run_pl_ner.py",
        "examples/movement-pruning/masked_run_glue.py",
        "examples/text-classification/run_xnli.py",
        "src/transformers/modeling_auto.py",
        "src/transformers/trainer.py",
        "src/transformers/data/processors/utils.py",
        "src/transformers/modeling_tf_flaubert.py",
        "src/transformers/data/metrics/squad_metrics.py",
        "examples/text-generation/pplm/run_pplm.py",
        "examples/question-answering/run_squad.py",
        "templates/adding_a_new_example_script/utils_xxx.py",
        "src/transformers/modeling_t5.py",
        "src/transformers/configuration_bert.py",
        "examples/text-generation/run_generation.py",
        "examples/contrib/run_transfo_xl.py",
        "src/transformers/modeling_tf_gpt2.py",
        "transformers/hubconf.py",
        "examples/language-modeling/run_language_modeling.py",
        "examples/token-classification/run_ner.py",
        "templates/adding_a_new_example_script/run_xxx.py",
        "examples/contrib/run_openai_gpt.py",
        "src/transformers/configuration_flaubert.py",
        "src/transformers/modeling_flaubert.py",
        "src/transformers/convert_xlnet_original_tf_checkpoint_to_pytorch.py",
        "examples/summarization/finetune.py",
        "src/transformers/modeling_utils.py",
        "src/transformers/modeling_tf_utils.py",
        "src/transformers/modeling_openai.py",
        "src/transformers/data/data_collator.py",
        "examples/summarization/bertabs/modeling_bertabs.py",
        "examples/distillation/scripts/extract_distilbert.py",
        "examples/adversarial/run_hans.py",
        "examples/multiple-choice/run_multiple_choice.py",
        "src/transformers/modeling_tf_openai.py",
        "examples/token-classification/run_tf_ner.py",
        "src/transformers/modeling_tf_xlnet.py",
        "src/transformers/modeling_tf_distilbert.py",
        "src/transformers/modeling_bert.py",
        "examples/multiple-choice/run_tf_multiple_choice.py",
        "transformers/setup.py"
    ],
    "3_final_combined_files": [
        "src/transformers/data/data_collator.py",
        "examples/text-classification/run_pl_glue.py",
        "examples/text-classification/run_glue.py",
        "examples/text-classification/run_tf_glue.py"
    ],
    "4_related_elements": {
        "src/transformers/data/data_collator.py": [
            "function: default_data_collator"
        ],
        "examples/text-classification/run_glue.py": [
            "function: main"
        ],
        "examples/text-classification/run_pl_glue.py": [
            "class: GLUETransformer"
        ]
    },
    "5_sampled_edit_locs_and_patches": [
        {
            "sample_index": 0,
            "edit_locs": {
                "src/transformers/data/data_collator.py": [
                    "function: default_data_collator\nline: 45\nline: 47\nline: 48\nline: 52\nline: 53"
                ],
                "examples/text-classification/run_pl_glue.py": [
                    ""
                ],
                "examples/text-classification/run_glue.py": [
                    ""
                ]
            },
            "patches": [
                "diff --git a/src/transformers/data/data_collator.py b/src/transformers/data/data_collator.py\nindex 98221c7..356de4a 100644\n--- a/src/transformers/data/data_collator.py\n+++ b/src/transformers/data/data_collator.py\n@@ -42,10 +42,15 @@ def default_data_collator(features: List[InputDataClass]) -> Dict[str, torch.Ten\n     # Special handling for labels.\n     # Ensure that tensor is created with the correct type\n     # (it should be automatically the case, but let's make sure of it.)\n-    if \"label\" in first:\n+    # Only create labels tensor if all samples have a non-None label/label_ids.\n+    if \"label\" in first and first[\"label\"] is not None and all(f[\"label\"] is not None for f in features):\n         dtype = torch.long if type(first[\"label\"]) is int else torch.float\n         batch[\"labels\"] = torch.tensor([f[\"label\"] for f in features], dtype=dtype)\n-    elif \"label_ids\" in first:\n+    elif (\n+        \"label_ids\" in first\n+        and first[\"label_ids\"] is not None\n+        and all(f[\"label_ids\"] is not None for f in features)\n+    ):\n         if isinstance(first[\"label_ids\"], torch.Tensor):\n             batch[\"labels\"] = torch.stack([f[\"label_ids\"] for f in features])\n         else:\n",
                "diff --git a/src/transformers/data/data_collator.py b/src/transformers/data/data_collator.py\nindex 98221c7..38aa1f4 100644\n--- a/src/transformers/data/data_collator.py\n+++ b/src/transformers/data/data_collator.py\n@@ -42,15 +42,20 @@ def default_data_collator(features: List[InputDataClass]) -> Dict[str, torch.Ten\n     # Special handling for labels.\n     # Ensure that tensor is created with the correct type\n     # (it should be automatically the case, but let's make sure of it.)\n-    if \"label\" in first:\n-        dtype = torch.long if type(first[\"label\"]) is int else torch.float\n-        batch[\"labels\"] = torch.tensor([f[\"label\"] for f in features], dtype=dtype)\n-    elif \"label_ids\" in first:\n+    if \"label\" in first and first[\"label\"] is not None:\n+        # Only create labels tensor if all labels are not None\n+        if all(f[\"label\"] is not None for f in features):\n+            dtype = torch.long if isinstance(first[\"label\"], int) else torch.float\n+            batch[\"labels\"] = torch.tensor([f[\"label\"] for f in features], dtype=dtype)\n+    elif \"label_ids\" in first and first[\"label_ids\"] is not None:\n         if isinstance(first[\"label_ids\"], torch.Tensor):\n             batch[\"labels\"] = torch.stack([f[\"label_ids\"] for f in features])\n         else:\n-            dtype = torch.long if type(first[\"label_ids\"][0]) is int else torch.float\n-            batch[\"labels\"] = torch.tensor([f[\"label_ids\"] for f in features], dtype=dtype)\n+            # Only create labels tensor if all label_ids are not None\n+            if all(f[\"label_ids\"] is not None for f in features):\n+                first_label = first[\"label_ids\"][0] if isinstance(first[\"label_ids\"], (list, tuple)) and len(first[\"label_ids\"]) > 0 else first[\"label_ids\"]\n+                dtype = torch.long if isinstance(first_label, int) else torch.float\n+                batch[\"labels\"] = torch.tensor([f[\"label_ids\"] for f in features], dtype=dtype)\n \n     # Handling of all other possible keys.\n     # Again, we will use the first element to figure out which key/values are not None for this model.\n"
            ]
        },
        {
            "sample_index": 1,
            "edit_locs": {
                "src/transformers/data/data_collator.py": [
                    "function: default_data_collator\nline: 45\nline: 46\nline: 47\nline: 48\nline: 52\nline: 53"
                ],
                "examples/text-classification/run_pl_glue.py": [
                    ""
                ],
                "examples/text-classification/run_glue.py": [
                    ""
                ]
            },
            "patches": [
                "diff --git a/src/transformers/data/data_collator.py b/src/transformers/data/data_collator.py\nindex 98221c7..ca1f030 100644\n--- a/src/transformers/data/data_collator.py\n+++ b/src/transformers/data/data_collator.py\n@@ -42,14 +42,14 @@ def default_data_collator(features: List[InputDataClass]) -> Dict[str, torch.Ten\n     # Special handling for labels.\n     # Ensure that tensor is created with the correct type\n     # (it should be automatically the case, but let's make sure of it.)\n-    if \"label\" in first:\n-        dtype = torch.long if type(first[\"label\"]) is int else torch.float\n+    if \"label\" in first and first[\"label\"] is not None:\n+        dtype = torch.long if isinstance(first[\"label\"], int) else torch.float\n         batch[\"labels\"] = torch.tensor([f[\"label\"] for f in features], dtype=dtype)\n     elif \"label_ids\" in first:\n         if isinstance(first[\"label_ids\"], torch.Tensor):\n             batch[\"labels\"] = torch.stack([f[\"label_ids\"] for f in features])\n-        else:\n-            dtype = torch.long if type(first[\"label_ids\"][0]) is int else torch.float\n+        elif first[\"label_ids\"] is not None:\n+            dtype = torch.long if isinstance(first[\"label_ids\"][0], int) else torch.float\n             batch[\"labels\"] = torch.tensor([f[\"label_ids\"] for f in features], dtype=dtype)\n \n     # Handling of all other possible keys.\n",
                "diff --git a/src/transformers/data/data_collator.py b/src/transformers/data/data_collator.py\nindex 98221c7..476af90 100644\n--- a/src/transformers/data/data_collator.py\n+++ b/src/transformers/data/data_collator.py\n@@ -42,10 +42,13 @@ def default_data_collator(features: List[InputDataClass]) -> Dict[str, torch.Ten\n     # Special handling for labels.\n     # Ensure that tensor is created with the correct type\n     # (it should be automatically the case, but let's make sure of it.)\n-    if \"label\" in first:\n-        dtype = torch.long if type(first[\"label\"]) is int else torch.float\n-        batch[\"labels\"] = torch.tensor([f[\"label\"] for f in features], dtype=dtype)\n-    elif \"label_ids\" in first:\n+    if \"label\" in first and first[\"label\"] is not None:\n+        labels = [f[\"label\"] for f in features]\n+        # If any label is None, skip creating the labels tensor (e.g., test sets without labels)\n+        if not any(l is None for l in labels):\n+            dtype = torch.long if type(first[\"label\"]) is int else torch.float\n+            batch[\"labels\"] = torch.tensor(labels, dtype=dtype)\n+    elif \"label_ids\" in first and first[\"label_ids\"] is not None:\n         if isinstance(first[\"label_ids\"], torch.Tensor):\n             batch[\"labels\"] = torch.stack([f[\"label_ids\"] for f in features])\n         else:\n"
            ]
        }
    ],
    "6_final_selected_patch": "diff --git a/src/transformers/data/data_collator.py b/src/transformers/data/data_collator.py\nindex 98221c7..356de4a 100644\n--- a/src/transformers/data/data_collator.py\n+++ b/src/transformers/data/data_collator.py\n@@ -42,10 +42,15 @@ def default_data_collator(features: List[InputDataClass]) -> Dict[str, torch.Ten\n     # Special handling for labels.\n     # Ensure that tensor is created with the correct type\n     # (it should be automatically the case, but let's make sure of it.)\n-    if \"label\" in first:\n+    # Only create labels tensor if all samples have a non-None label/label_ids.\n+    if \"label\" in first and first[\"label\"] is not None and all(f[\"label\"] is not None for f in features):\n         dtype = torch.long if type(first[\"label\"]) is int else torch.float\n         batch[\"labels\"] = torch.tensor([f[\"label\"] for f in features], dtype=dtype)\n-    elif \"label_ids\" in first:\n+    elif (\n+        \"label_ids\" in first\n+        and first[\"label_ids\"] is not None\n+        and all(f[\"label_ids\"] is not None for f in features)\n+    ):\n         if isinstance(first[\"label_ids\"], torch.Tensor):\n             batch[\"labels\"] = torch.stack([f[\"label_ids\"] for f in features])\n         else:\n"
}