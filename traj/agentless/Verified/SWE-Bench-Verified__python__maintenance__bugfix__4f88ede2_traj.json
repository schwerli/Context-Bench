{
  "instance_id": "SWE-Bench-Verified__python__maintenance__bugfix__4f88ede2",
  "original_id": "scikit-learn__scikit-learn-15100",
  "1_model_selected_files": [
    "sklearn/feature_extraction/text.py"
  ],
  "2_embedding_selected_files": [
    "sklearn/feature_extraction/text.py",
    "examples/text/plot_hashing_vs_dict_vectorizer.py",
    "examples/neighbors/approximate_nearest_neighbors.py",
    "examples/text/plot_document_classification_20newsgroups.py",
    "doc/tutorial/machine_learning_map/pyparsing.py",
    "sklearn/feature_extraction/dict_vectorizer.py",
    "examples/compose/plot_column_transformer.py",
    "examples/cluster/plot_kmeans_assumptions.py",
    "examples/classification/plot_lda.py",
    "benchmarks/bench_text_vectorizers.py",
    "examples/compose/plot_transformed_target.py",
    "examples/bicluster/plot_bicluster_newsgroups.py",
    "examples/preprocessing/plot_scaling_importance.py",
    "examples/applications/plot_out_of_core_classification.py",
    "examples/impute/plot_iterative_imputer_variants_comparison.py",
    "sklearn/feature_extraction/hashing.py",
    "examples/linear_model/plot_lasso_model_selection.py",
    "examples/text/plot_document_clustering.py",
    "examples/applications/plot_topics_extraction_with_nmf_lda.py",
    "examples/linear_model/plot_sparse_logistic_regression_20newsgroups.py",
    "examples/preprocessing/plot_all_scaling.py",
    "benchmarks/bench_lasso.py",
    "examples/plot_multilabel.py",
    "examples/inspection/plot_permutation_importance.py",
    "examples/neighbors/plot_nca_classification.py",
    "benchmarks/bench_plot_lasso_path.py",
    "examples/preprocessing/plot_discretization_classification.py",
    "examples/plot_johnson_lindenstrauss_bound.py",
    "examples/model_selection/plot_cv_indices.py",
    "examples/preprocessing/plot_discretization.py",
    "benchmarks/bench_plot_nmf.py",
    "benchmarks/bench_rcv1_logreg_convergence.py",
    "doc/conftest.py",
    "benchmarks/bench_hist_gradient_boosting_higgsboson.py",
    "examples/compose/plot_column_transformer_mixed_types.py",
    "doc/tutorial/text_analytics/solutions/exercise_01_language_train_model.py",
    "examples/preprocessing/plot_discretization_strategies.py",
    "examples/linear_model/plot_sgd_early_stopping.py",
    "examples/neighbors/plot_nca_dim_reduction.py",
    "examples/cluster/plot_adjusted_for_chance_measures.py",
    "examples/impute/plot_missing_values.py",
    "examples/cluster/plot_feature_agglomeration_vs_univariate_selection.py",
    "examples/cluster/plot_kmeans_silhouette_analysis.py",
    "scikit-learn/setup.py",
    "benchmarks/bench_plot_randomized_svd.py",
    "benchmarks/bench_20newsgroups.py",
    "examples/model_selection/plot_nested_cross_validation_iris.py",
    "doc/tutorial/text_analytics/skeletons/exercise_01_language_train_model.py",
    "examples/decomposition/plot_image_denoising.py",
    "examples/manifold/plot_lle_digits.py",
    "benchmarks/bench_tsne_mnist.py",
    "examples/datasets/plot_random_multilabel_dataset.py",
    "examples/model_selection/plot_confusion_matrix.py",
    "examples/decomposition/plot_pca_vs_fa_model_selection.py",
    "benchmarks/bench_saga.py",
    "examples/plot_kernel_approximation.py",
    "examples/ensemble/plot_gradient_boosting_early_stopping.py",
    "examples/cluster/plot_digits_linkage.py",
    "examples/decomposition/plot_faces_decomposition.py",
    "benchmarks/bench_hist_gradient_boosting.py",
    "examples/calibration/plot_compare_calibration.py",
    "examples/cross_decomposition/plot_compare_cross_decomposition.py",
    "examples/manifold/plot_t_sne_perplexity.py",
    "examples/model_selection/plot_train_error_vs_test_error.py",
    "examples/preprocessing/plot_function_transformer.py",
    "examples/classification/plot_classifier_comparison.py",
    "examples/cluster/plot_agglomerative_clustering_metrics.py",
    "sklearn/feature_extraction/__init__.py",
    "benchmarks/bench_plot_svd.py",
    "examples/applications/plot_prediction_latency.py",
    "examples/classification/plot_digits_classification.py",
    "examples/feature_selection/plot_permutation_test_for_classification.py",
    "examples/multioutput/plot_classifier_chain_yeast.py",
    "examples/calibration/plot_calibration_multiclass.py",
    "examples/linear_model/plot_lasso_coordinate_descent_path.py",
    "examples/applications/plot_model_complexity_influence.py",
    "benchmarks/bench_tree.py",
    "examples/ensemble/plot_feature_transformation.py"
  ],
  "3_final_combined_files": [
    "sklearn/feature_extraction/text.py",
    "examples/text/plot_hashing_vs_dict_vectorizer.py",
    "examples/neighbors/approximate_nearest_neighbors.py"
  ],
  "4_related_elements": {
    "sklearn/feature_extraction/text.py": [
      "function: strip_accents_unicode\nfunction: strip_accents_ascii\nfunction: _preprocess\nfunction: _analyze\nclass: VectorizerMixin\nclass: HashingVectorizer\nclass: CountVectorizer\nclass: TfidfVectorizer"
    ],
    "examples/text/plot_hashing_vs_dict_vectorizer.py": [
      ""
    ],
    "examples/neighbors/approximate_nearest_neighbors.py": [
      ""
    ]
  },
  "5_sampled_edit_locs_and_patches": [
    {
      "sample_index": 0,
      "edit_locs": {
        "sklearn/feature_extraction/text.py": [
          "\nfunction: strip_accents_unicode\nline: 132\nline: 133\nline: 134\nline: 135\nline: 136"
        ]
      },
      "patches": [
        "diff --git a/sklearn/feature_extraction/text.py b/sklearn/feature_extraction/text.py\nindex d954f48..f6d64db 100644\n--- a/sklearn/feature_extraction/text.py\n+++ b/sklearn/feature_extraction/text.py\n@@ -130,10 +130,7 @@ def strip_accents_unicode(s):\n         ASCII equivalent.\n     \"\"\"\n     normalized = unicodedata.normalize('NFKD', s)\n-    if normalized == s:\n-        return s\n-    else:\n-        return ''.join([c for c in normalized if not unicodedata.combining(c)])\n+    return ''.join([c for c in normalized if not unicodedata.combining(c)])\n \n \n def strip_accents_ascii(s):\n",
        "diff --git a/sklearn/feature_extraction/text.py b/sklearn/feature_extraction/text.py\nindex d954f48..f6d64db 100644\n--- a/sklearn/feature_extraction/text.py\n+++ b/sklearn/feature_extraction/text.py\n@@ -130,10 +130,7 @@ def strip_accents_unicode(s):\n         ASCII equivalent.\n     \"\"\"\n     normalized = unicodedata.normalize('NFKD', s)\n-    if normalized == s:\n-        return s\n-    else:\n-        return ''.join([c for c in normalized if not unicodedata.combining(c)])\n+    return ''.join([c for c in normalized if not unicodedata.combining(c)])\n \n \n def strip_accents_ascii(s):\n",
        "diff --git a/sklearn/feature_extraction/text.py b/sklearn/feature_extraction/text.py\nindex d954f48..f6d64db 100644\n--- a/sklearn/feature_extraction/text.py\n+++ b/sklearn/feature_extraction/text.py\n@@ -130,10 +130,7 @@ def strip_accents_unicode(s):\n         ASCII equivalent.\n     \"\"\"\n     normalized = unicodedata.normalize('NFKD', s)\n-    if normalized == s:\n-        return s\n-    else:\n-        return ''.join([c for c in normalized if not unicodedata.combining(c)])\n+    return ''.join([c for c in normalized if not unicodedata.combining(c)])\n \n \n def strip_accents_ascii(s):\n",
        "diff --git a/sklearn/feature_extraction/text.py b/sklearn/feature_extraction/text.py\nindex d954f48..f6d64db 100644\n--- a/sklearn/feature_extraction/text.py\n+++ b/sklearn/feature_extraction/text.py\n@@ -130,10 +130,7 @@ def strip_accents_unicode(s):\n         ASCII equivalent.\n     \"\"\"\n     normalized = unicodedata.normalize('NFKD', s)\n-    if normalized == s:\n-        return s\n-    else:\n-        return ''.join([c for c in normalized if not unicodedata.combining(c)])\n+    return ''.join([c for c in normalized if not unicodedata.combining(c)])\n \n \n def strip_accents_ascii(s):\n",
        "diff --git a/sklearn/feature_extraction/text.py b/sklearn/feature_extraction/text.py\nindex d954f48..a72b397 100644\n--- a/sklearn/feature_extraction/text.py\n+++ b/sklearn/feature_extraction/text.py\n@@ -129,11 +129,10 @@ def strip_accents_unicode(s):\n         Remove accentuated char for any unicode symbol that has a direct\n         ASCII equivalent.\n     \"\"\"\n+    # Always normalize to NFKD and remove combining marks, even if the input\n+    # string is already in NFKD form.\n     normalized = unicodedata.normalize('NFKD', s)\n-    if normalized == s:\n-        return s\n-    else:\n-        return ''.join([c for c in normalized if not unicodedata.combining(c)])\n+    return ''.join(c for c in normalized if not unicodedata.combining(c))\n \n \n def strip_accents_ascii(s):\n",
        "diff --git a/sklearn/feature_extraction/text.py b/sklearn/feature_extraction/text.py\nindex d954f48..f6d64db 100644\n--- a/sklearn/feature_extraction/text.py\n+++ b/sklearn/feature_extraction/text.py\n@@ -130,10 +130,7 @@ def strip_accents_unicode(s):\n         ASCII equivalent.\n     \"\"\"\n     normalized = unicodedata.normalize('NFKD', s)\n-    if normalized == s:\n-        return s\n-    else:\n-        return ''.join([c for c in normalized if not unicodedata.combining(c)])\n+    return ''.join([c for c in normalized if not unicodedata.combining(c)])\n \n \n def strip_accents_ascii(s):\n",
        "diff --git a/sklearn/feature_extraction/text.py b/sklearn/feature_extraction/text.py\nindex d954f48..e349b9d 100644\n--- a/sklearn/feature_extraction/text.py\n+++ b/sklearn/feature_extraction/text.py\n@@ -130,10 +130,8 @@ def strip_accents_unicode(s):\n         ASCII equivalent.\n     \"\"\"\n     normalized = unicodedata.normalize('NFKD', s)\n-    if normalized == s:\n-        return s\n-    else:\n-        return ''.join([c for c in normalized if not unicodedata.combining(c)])\n+    # Always remove combining marks, even if the input is already in NFKD form\n+    return ''.join([c for c in normalized if not unicodedata.combining(c)])\n \n \n def strip_accents_ascii(s):\n",
        "diff --git a/sklearn/feature_extraction/text.py b/sklearn/feature_extraction/text.py\nindex d954f48..c720814 100644\n--- a/sklearn/feature_extraction/text.py\n+++ b/sklearn/feature_extraction/text.py\n@@ -130,10 +130,8 @@ def strip_accents_unicode(s):\n         ASCII equivalent.\n     \"\"\"\n     normalized = unicodedata.normalize('NFKD', s)\n-    if normalized == s:\n-        return s\n-    else:\n-        return ''.join([c for c in normalized if not unicodedata.combining(c)])\n+    # Always strip combining marks, even if the input is already in NFKD form.\n+    return ''.join(c for c in normalized if not unicodedata.combining(c))\n \n \n def strip_accents_ascii(s):\n",
        "diff --git a/sklearn/feature_extraction/text.py b/sklearn/feature_extraction/text.py\nindex d954f48..f03420d 100644\n--- a/sklearn/feature_extraction/text.py\n+++ b/sklearn/feature_extraction/text.py\n@@ -130,10 +130,9 @@ def strip_accents_unicode(s):\n         ASCII equivalent.\n     \"\"\"\n     normalized = unicodedata.normalize('NFKD', s)\n-    if normalized == s:\n-        return s\n-    else:\n-        return ''.join([c for c in normalized if not unicodedata.combining(c)])\n+    # Always remove combining characters (accents), even if input is already\n+    # in NFKD form.\n+    return ''.join([c for c in normalized if not unicodedata.combining(c)])\n \n \n def strip_accents_ascii(s):\n",
        "diff --git a/sklearn/feature_extraction/text.py b/sklearn/feature_extraction/text.py\nindex d954f48..2d07b03 100644\n--- a/sklearn/feature_extraction/text.py\n+++ b/sklearn/feature_extraction/text.py\n@@ -130,10 +130,7 @@ def strip_accents_unicode(s):\n         ASCII equivalent.\n     \"\"\"\n     normalized = unicodedata.normalize('NFKD', s)\n-    if normalized == s:\n-        return s\n-    else:\n-        return ''.join([c for c in normalized if not unicodedata.combining(c)])\n+    return ''.join(c for c in normalized if not unicodedata.combining(c))\n \n \n def strip_accents_ascii(s):\n"
      ]
    },
    {
      "sample_index": 1,
      "edit_locs": {
        "sklearn/feature_extraction/text.py": [
          "\nfunction: strip_accents_unicode\nline: 133\nline: 134\nline: 135\nline: 136"
        ]
      },
      "patches": [
        "diff --git a/sklearn/feature_extraction/text.py b/sklearn/feature_extraction/text.py\nindex d954f48..f6d64db 100644\n--- a/sklearn/feature_extraction/text.py\n+++ b/sklearn/feature_extraction/text.py\n@@ -130,10 +130,7 @@ def strip_accents_unicode(s):\n         ASCII equivalent.\n     \"\"\"\n     normalized = unicodedata.normalize('NFKD', s)\n-    if normalized == s:\n-        return s\n-    else:\n-        return ''.join([c for c in normalized if not unicodedata.combining(c)])\n+    return ''.join([c for c in normalized if not unicodedata.combining(c)])\n \n \n def strip_accents_ascii(s):\n",
        "diff --git a/sklearn/feature_extraction/text.py b/sklearn/feature_extraction/text.py\nindex d954f48..442373e 100644\n--- a/sklearn/feature_extraction/text.py\n+++ b/sklearn/feature_extraction/text.py\n@@ -130,10 +130,9 @@ def strip_accents_unicode(s):\n         ASCII equivalent.\n     \"\"\"\n     normalized = unicodedata.normalize('NFKD', s)\n-    if normalized == s:\n-        return s\n-    else:\n-        return ''.join([c for c in normalized if not unicodedata.combining(c)])\n+    # Always strip combining characters after NFKD normalization,\n+    # even if the input is already in NFKD form.\n+    return ''.join([c for c in normalized if not unicodedata.combining(c)])\n \n \n def strip_accents_ascii(s):\n",
        "diff --git a/sklearn/feature_extraction/text.py b/sklearn/feature_extraction/text.py\nindex d954f48..264bcfc 100644\n--- a/sklearn/feature_extraction/text.py\n+++ b/sklearn/feature_extraction/text.py\n@@ -129,11 +129,10 @@ def strip_accents_unicode(s):\n         Remove accentuated char for any unicode symbol that has a direct\n         ASCII equivalent.\n     \"\"\"\n+    # Always normalize to NFKD and strip combining marks so that both\n+    # precomposed characters and already-decomposed sequences are handled.\n     normalized = unicodedata.normalize('NFKD', s)\n-    if normalized == s:\n-        return s\n-    else:\n-        return ''.join([c for c in normalized if not unicodedata.combining(c)])\n+    return ''.join([c for c in normalized if not unicodedata.combining(c)])\n \n \n def strip_accents_ascii(s):\n",
        "diff --git a/sklearn/feature_extraction/text.py b/sklearn/feature_extraction/text.py\nindex d954f48..249ba54 100644\n--- a/sklearn/feature_extraction/text.py\n+++ b/sklearn/feature_extraction/text.py\n@@ -130,10 +130,10 @@ def strip_accents_unicode(s):\n         ASCII equivalent.\n     \"\"\"\n     normalized = unicodedata.normalize('NFKD', s)\n-    if normalized == s:\n-        return s\n-    else:\n-        return ''.join([c for c in normalized if not unicodedata.combining(c)])\n+    # Always remove combining marks after normalization, even if the input is\n+    # already in NFKD form. This ensures visually identical strings with\n+    # precomposed or combining accents normalize to the same result.\n+    return ''.join([c for c in normalized if not unicodedata.combining(c)])\n \n \n def strip_accents_ascii(s):\n",
        "diff --git a/sklearn/feature_extraction/text.py b/sklearn/feature_extraction/text.py\nindex d954f48..2d07b03 100644\n--- a/sklearn/feature_extraction/text.py\n+++ b/sklearn/feature_extraction/text.py\n@@ -130,10 +130,7 @@ def strip_accents_unicode(s):\n         ASCII equivalent.\n     \"\"\"\n     normalized = unicodedata.normalize('NFKD', s)\n-    if normalized == s:\n-        return s\n-    else:\n-        return ''.join([c for c in normalized if not unicodedata.combining(c)])\n+    return ''.join(c for c in normalized if not unicodedata.combining(c))\n \n \n def strip_accents_ascii(s):\n",
        "diff --git a/sklearn/feature_extraction/text.py b/sklearn/feature_extraction/text.py\nindex d954f48..c46cd3d 100644\n--- a/sklearn/feature_extraction/text.py\n+++ b/sklearn/feature_extraction/text.py\n@@ -129,11 +129,11 @@ def strip_accents_unicode(s):\n         Remove accentuated char for any unicode symbol that has a direct\n         ASCII equivalent.\n     \"\"\"\n+    # Normalize to NFKD and remove combining marks even if the input is already\n+    # in normalized form. This ensures that both precomposed and decomposed\n+    # representations (e.g., \"ñ\" and \"ñ\") are stripped consistently.\n     normalized = unicodedata.normalize('NFKD', s)\n-    if normalized == s:\n-        return s\n-    else:\n-        return ''.join([c for c in normalized if not unicodedata.combining(c)])\n+    return ''.join(c for c in normalized if not unicodedata.combining(c))\n \n \n def strip_accents_ascii(s):\n",
        "diff --git a/sklearn/feature_extraction/text.py b/sklearn/feature_extraction/text.py\nindex d954f48..edc3152 100644\n--- a/sklearn/feature_extraction/text.py\n+++ b/sklearn/feature_extraction/text.py\n@@ -130,10 +130,8 @@ def strip_accents_unicode(s):\n         ASCII equivalent.\n     \"\"\"\n     normalized = unicodedata.normalize('NFKD', s)\n-    if normalized == s:\n-        return s\n-    else:\n-        return ''.join([c for c in normalized if not unicodedata.combining(c)])\n+    # Always remove combining characters, even if s is already in NFKD form\n+    return ''.join([c for c in normalized if not unicodedata.combining(c)])\n \n \n def strip_accents_ascii(s):\n",
        "diff --git a/sklearn/feature_extraction/text.py b/sklearn/feature_extraction/text.py\nindex d954f48..b914d8d 100644\n--- a/sklearn/feature_extraction/text.py\n+++ b/sklearn/feature_extraction/text.py\n@@ -129,11 +129,10 @@ def strip_accents_unicode(s):\n         Remove accentuated char for any unicode symbol that has a direct\n         ASCII equivalent.\n     \"\"\"\n+    # Always remove combining characters after NFKD normalization,\n+    # even if the input string is already in NFKD form.\n     normalized = unicodedata.normalize('NFKD', s)\n-    if normalized == s:\n-        return s\n-    else:\n-        return ''.join([c for c in normalized if not unicodedata.combining(c)])\n+    return ''.join([c for c in normalized if not unicodedata.combining(c)])\n \n \n def strip_accents_ascii(s):\n",
        "diff --git a/sklearn/feature_extraction/text.py b/sklearn/feature_extraction/text.py\nindex d954f48..cd393f5 100644\n--- a/sklearn/feature_extraction/text.py\n+++ b/sklearn/feature_extraction/text.py\n@@ -130,10 +130,9 @@ def strip_accents_unicode(s):\n         ASCII equivalent.\n     \"\"\"\n     normalized = unicodedata.normalize('NFKD', s)\n-    if normalized == s:\n-        return s\n-    else:\n-        return ''.join([c for c in normalized if not unicodedata.combining(c)])\n+    # Always remove combining marks after normalization, even if the input\n+    # is already in NFKD form.\n+    return ''.join([c for c in normalized if not unicodedata.combining(c)])\n \n \n def strip_accents_ascii(s):\n",
        "diff --git a/sklearn/feature_extraction/text.py b/sklearn/feature_extraction/text.py\nindex d954f48..f6d64db 100644\n--- a/sklearn/feature_extraction/text.py\n+++ b/sklearn/feature_extraction/text.py\n@@ -130,10 +130,7 @@ def strip_accents_unicode(s):\n         ASCII equivalent.\n     \"\"\"\n     normalized = unicodedata.normalize('NFKD', s)\n-    if normalized == s:\n-        return s\n-    else:\n-        return ''.join([c for c in normalized if not unicodedata.combining(c)])\n+    return ''.join([c for c in normalized if not unicodedata.combining(c)])\n \n \n def strip_accents_ascii(s):\n"
      ]
    },
    {
      "sample_index": 2,
      "edit_locs": {
        "sklearn/feature_extraction/text.py": [
          "\nfunction: strip_accents_unicode\nline: 133\nline: 134\nline: 135\nline: 136"
        ]
      },
      "patches": [
        "diff --git a/sklearn/feature_extraction/text.py b/sklearn/feature_extraction/text.py\nindex d954f48..f6d64db 100644\n--- a/sklearn/feature_extraction/text.py\n+++ b/sklearn/feature_extraction/text.py\n@@ -130,10 +130,7 @@ def strip_accents_unicode(s):\n         ASCII equivalent.\n     \"\"\"\n     normalized = unicodedata.normalize('NFKD', s)\n-    if normalized == s:\n-        return s\n-    else:\n-        return ''.join([c for c in normalized if not unicodedata.combining(c)])\n+    return ''.join([c for c in normalized if not unicodedata.combining(c)])\n \n \n def strip_accents_ascii(s):\n",
        "diff --git a/sklearn/feature_extraction/text.py b/sklearn/feature_extraction/text.py\nindex d954f48..93f9e22 100644\n--- a/sklearn/feature_extraction/text.py\n+++ b/sklearn/feature_extraction/text.py\n@@ -130,10 +130,8 @@ def strip_accents_unicode(s):\n         ASCII equivalent.\n     \"\"\"\n     normalized = unicodedata.normalize('NFKD', s)\n-    if normalized == s:\n-        return s\n-    else:\n-        return ''.join([c for c in normalized if not unicodedata.combining(c)])\n+    # Always strip combining marks even if the input was already in NFKD form.\n+    return ''.join([c for c in normalized if not unicodedata.combining(c)])\n \n \n def strip_accents_ascii(s):\n",
        "diff --git a/sklearn/feature_extraction/text.py b/sklearn/feature_extraction/text.py\nindex d954f48..edc3152 100644\n--- a/sklearn/feature_extraction/text.py\n+++ b/sklearn/feature_extraction/text.py\n@@ -130,10 +130,8 @@ def strip_accents_unicode(s):\n         ASCII equivalent.\n     \"\"\"\n     normalized = unicodedata.normalize('NFKD', s)\n-    if normalized == s:\n-        return s\n-    else:\n-        return ''.join([c for c in normalized if not unicodedata.combining(c)])\n+    # Always remove combining characters, even if s is already in NFKD form\n+    return ''.join([c for c in normalized if not unicodedata.combining(c)])\n \n \n def strip_accents_ascii(s):\n",
        "diff --git a/sklearn/feature_extraction/text.py b/sklearn/feature_extraction/text.py\nindex d954f48..b5c370e 100644\n--- a/sklearn/feature_extraction/text.py\n+++ b/sklearn/feature_extraction/text.py\n@@ -130,10 +130,8 @@ def strip_accents_unicode(s):\n         ASCII equivalent.\n     \"\"\"\n     normalized = unicodedata.normalize('NFKD', s)\n-    if normalized == s:\n-        return s\n-    else:\n-        return ''.join([c for c in normalized if not unicodedata.combining(c)])\n+    # Always remove combining marks, even if the input is already in NFKD form.\n+    return ''.join(c for c in normalized if not unicodedata.combining(c))\n \n \n def strip_accents_ascii(s):\n",
        "diff --git a/sklearn/feature_extraction/text.py b/sklearn/feature_extraction/text.py\nindex d954f48..2d07b03 100644\n--- a/sklearn/feature_extraction/text.py\n+++ b/sklearn/feature_extraction/text.py\n@@ -130,10 +130,7 @@ def strip_accents_unicode(s):\n         ASCII equivalent.\n     \"\"\"\n     normalized = unicodedata.normalize('NFKD', s)\n-    if normalized == s:\n-        return s\n-    else:\n-        return ''.join([c for c in normalized if not unicodedata.combining(c)])\n+    return ''.join(c for c in normalized if not unicodedata.combining(c))\n \n \n def strip_accents_ascii(s):\n",
        "diff --git a/sklearn/feature_extraction/text.py b/sklearn/feature_extraction/text.py\nindex d954f48..2b87074 100644\n--- a/sklearn/feature_extraction/text.py\n+++ b/sklearn/feature_extraction/text.py\n@@ -130,10 +130,9 @@ def strip_accents_unicode(s):\n         ASCII equivalent.\n     \"\"\"\n     normalized = unicodedata.normalize('NFKD', s)\n-    if normalized == s:\n-        return s\n-    else:\n-        return ''.join([c for c in normalized if not unicodedata.combining(c)])\n+    # Always remove combining marks (accents) from the normalized string,\n+    # even if the input was already in NFKD form.\n+    return ''.join(c for c in normalized if not unicodedata.combining(c))\n \n \n def strip_accents_ascii(s):\n",
        "diff --git a/sklearn/feature_extraction/text.py b/sklearn/feature_extraction/text.py\nindex d954f48..35d912e 100644\n--- a/sklearn/feature_extraction/text.py\n+++ b/sklearn/feature_extraction/text.py\n@@ -130,10 +130,8 @@ def strip_accents_unicode(s):\n         ASCII equivalent.\n     \"\"\"\n     normalized = unicodedata.normalize('NFKD', s)\n-    if normalized == s:\n-        return s\n-    else:\n-        return ''.join([c for c in normalized if not unicodedata.combining(c)])\n+    # Always strip combining marks, even if the input is already in NFKD form.\n+    return ''.join([c for c in normalized if not unicodedata.combining(c)])\n \n \n def strip_accents_ascii(s):\n",
        "diff --git a/sklearn/feature_extraction/text.py b/sklearn/feature_extraction/text.py\nindex d954f48..f6d64db 100644\n--- a/sklearn/feature_extraction/text.py\n+++ b/sklearn/feature_extraction/text.py\n@@ -130,10 +130,7 @@ def strip_accents_unicode(s):\n         ASCII equivalent.\n     \"\"\"\n     normalized = unicodedata.normalize('NFKD', s)\n-    if normalized == s:\n-        return s\n-    else:\n-        return ''.join([c for c in normalized if not unicodedata.combining(c)])\n+    return ''.join([c for c in normalized if not unicodedata.combining(c)])\n \n \n def strip_accents_ascii(s):\n",
        "diff --git a/sklearn/feature_extraction/text.py b/sklearn/feature_extraction/text.py\nindex d954f48..2d07b03 100644\n--- a/sklearn/feature_extraction/text.py\n+++ b/sklearn/feature_extraction/text.py\n@@ -130,10 +130,7 @@ def strip_accents_unicode(s):\n         ASCII equivalent.\n     \"\"\"\n     normalized = unicodedata.normalize('NFKD', s)\n-    if normalized == s:\n-        return s\n-    else:\n-        return ''.join([c for c in normalized if not unicodedata.combining(c)])\n+    return ''.join(c for c in normalized if not unicodedata.combining(c))\n \n \n def strip_accents_ascii(s):\n",
        "diff --git a/sklearn/feature_extraction/text.py b/sklearn/feature_extraction/text.py\nindex d954f48..8f3341c 100644\n--- a/sklearn/feature_extraction/text.py\n+++ b/sklearn/feature_extraction/text.py\n@@ -130,10 +130,9 @@ def strip_accents_unicode(s):\n         ASCII equivalent.\n     \"\"\"\n     normalized = unicodedata.normalize('NFKD', s)\n-    if normalized == s:\n-        return s\n-    else:\n-        return ''.join([c for c in normalized if not unicodedata.combining(c)])\n+    # Always strip combining marks from the normalized form, even if the input\n+    # is already in NFKD form.\n+    return ''.join([c for c in normalized if not unicodedata.combining(c)])\n \n \n def strip_accents_ascii(s):\n"
      ]
    },
    {
      "sample_index": 3,
      "edit_locs": {
        "sklearn/feature_extraction/text.py": [
          "\nfunction: strip_accents_unicode\nline: 133\nline: 134\nline: 135\nline: 136"
        ]
      },
      "patches": [
        "diff --git a/sklearn/feature_extraction/text.py b/sklearn/feature_extraction/text.py\nindex d954f48..147941d 100644\n--- a/sklearn/feature_extraction/text.py\n+++ b/sklearn/feature_extraction/text.py\n@@ -130,10 +130,9 @@ def strip_accents_unicode(s):\n         ASCII equivalent.\n     \"\"\"\n     normalized = unicodedata.normalize('NFKD', s)\n-    if normalized == s:\n-        return s\n-    else:\n-        return ''.join([c for c in normalized if not unicodedata.combining(c)])\n+    # Always strip combining characters after NFKD normalization,\n+    # even if the input was already normalized.\n+    return ''.join([c for c in normalized if not unicodedata.combining(c)])\n \n \n def strip_accents_ascii(s):\n",
        "diff --git a/sklearn/feature_extraction/text.py b/sklearn/feature_extraction/text.py\nindex d954f48..3bd6d78 100644\n--- a/sklearn/feature_extraction/text.py\n+++ b/sklearn/feature_extraction/text.py\n@@ -130,10 +130,9 @@ def strip_accents_unicode(s):\n         ASCII equivalent.\n     \"\"\"\n     normalized = unicodedata.normalize('NFKD', s)\n-    if normalized == s:\n-        return s\n-    else:\n-        return ''.join([c for c in normalized if not unicodedata.combining(c)])\n+    # Remove all combining characters (accents) after NFKD normalization,\n+    # even if the string was already in NFKD form.\n+    return ''.join([c for c in normalized if not unicodedata.combining(c)])\n \n \n def strip_accents_ascii(s):\n",
        "diff --git a/sklearn/feature_extraction/text.py b/sklearn/feature_extraction/text.py\nindex d954f48..f6d64db 100644\n--- a/sklearn/feature_extraction/text.py\n+++ b/sklearn/feature_extraction/text.py\n@@ -130,10 +130,7 @@ def strip_accents_unicode(s):\n         ASCII equivalent.\n     \"\"\"\n     normalized = unicodedata.normalize('NFKD', s)\n-    if normalized == s:\n-        return s\n-    else:\n-        return ''.join([c for c in normalized if not unicodedata.combining(c)])\n+    return ''.join([c for c in normalized if not unicodedata.combining(c)])\n \n \n def strip_accents_ascii(s):\n",
        "diff --git a/sklearn/feature_extraction/text.py b/sklearn/feature_extraction/text.py\nindex d954f48..f6d64db 100644\n--- a/sklearn/feature_extraction/text.py\n+++ b/sklearn/feature_extraction/text.py\n@@ -130,10 +130,7 @@ def strip_accents_unicode(s):\n         ASCII equivalent.\n     \"\"\"\n     normalized = unicodedata.normalize('NFKD', s)\n-    if normalized == s:\n-        return s\n-    else:\n-        return ''.join([c for c in normalized if not unicodedata.combining(c)])\n+    return ''.join([c for c in normalized if not unicodedata.combining(c)])\n \n \n def strip_accents_ascii(s):\n",
        "diff --git a/sklearn/feature_extraction/text.py b/sklearn/feature_extraction/text.py\nindex d954f48..f6d64db 100644\n--- a/sklearn/feature_extraction/text.py\n+++ b/sklearn/feature_extraction/text.py\n@@ -130,10 +130,7 @@ def strip_accents_unicode(s):\n         ASCII equivalent.\n     \"\"\"\n     normalized = unicodedata.normalize('NFKD', s)\n-    if normalized == s:\n-        return s\n-    else:\n-        return ''.join([c for c in normalized if not unicodedata.combining(c)])\n+    return ''.join([c for c in normalized if not unicodedata.combining(c)])\n \n \n def strip_accents_ascii(s):\n",
        "diff --git a/sklearn/feature_extraction/text.py b/sklearn/feature_extraction/text.py\nindex d954f48..f6d64db 100644\n--- a/sklearn/feature_extraction/text.py\n+++ b/sklearn/feature_extraction/text.py\n@@ -130,10 +130,7 @@ def strip_accents_unicode(s):\n         ASCII equivalent.\n     \"\"\"\n     normalized = unicodedata.normalize('NFKD', s)\n-    if normalized == s:\n-        return s\n-    else:\n-        return ''.join([c for c in normalized if not unicodedata.combining(c)])\n+    return ''.join([c for c in normalized if not unicodedata.combining(c)])\n \n \n def strip_accents_ascii(s):\n",
        "diff --git a/sklearn/feature_extraction/text.py b/sklearn/feature_extraction/text.py\nindex d954f48..f6d64db 100644\n--- a/sklearn/feature_extraction/text.py\n+++ b/sklearn/feature_extraction/text.py\n@@ -130,10 +130,7 @@ def strip_accents_unicode(s):\n         ASCII equivalent.\n     \"\"\"\n     normalized = unicodedata.normalize('NFKD', s)\n-    if normalized == s:\n-        return s\n-    else:\n-        return ''.join([c for c in normalized if not unicodedata.combining(c)])\n+    return ''.join([c for c in normalized if not unicodedata.combining(c)])\n \n \n def strip_accents_ascii(s):\n",
        "diff --git a/sklearn/feature_extraction/text.py b/sklearn/feature_extraction/text.py\nindex d954f48..b04cf2e 100644\n--- a/sklearn/feature_extraction/text.py\n+++ b/sklearn/feature_extraction/text.py\n@@ -130,10 +130,9 @@ def strip_accents_unicode(s):\n         ASCII equivalent.\n     \"\"\"\n     normalized = unicodedata.normalize('NFKD', s)\n-    if normalized == s:\n-        return s\n-    else:\n-        return ''.join([c for c in normalized if not unicodedata.combining(c)])\n+    # Remove all combining characters to strip accents, even if the input\n+    # is already in NFKD form.\n+    return ''.join([c for c in normalized if not unicodedata.combining(c)])\n \n \n def strip_accents_ascii(s):\n",
        "diff --git a/sklearn/feature_extraction/text.py b/sklearn/feature_extraction/text.py\nindex d954f48..2d07b03 100644\n--- a/sklearn/feature_extraction/text.py\n+++ b/sklearn/feature_extraction/text.py\n@@ -130,10 +130,7 @@ def strip_accents_unicode(s):\n         ASCII equivalent.\n     \"\"\"\n     normalized = unicodedata.normalize('NFKD', s)\n-    if normalized == s:\n-        return s\n-    else:\n-        return ''.join([c for c in normalized if not unicodedata.combining(c)])\n+    return ''.join(c for c in normalized if not unicodedata.combining(c))\n \n \n def strip_accents_ascii(s):\n",
        "diff --git a/sklearn/feature_extraction/text.py b/sklearn/feature_extraction/text.py\nindex d954f48..f6d64db 100644\n--- a/sklearn/feature_extraction/text.py\n+++ b/sklearn/feature_extraction/text.py\n@@ -130,10 +130,7 @@ def strip_accents_unicode(s):\n         ASCII equivalent.\n     \"\"\"\n     normalized = unicodedata.normalize('NFKD', s)\n-    if normalized == s:\n-        return s\n-    else:\n-        return ''.join([c for c in normalized if not unicodedata.combining(c)])\n+    return ''.join([c for c in normalized if not unicodedata.combining(c)])\n \n \n def strip_accents_ascii(s):\n"
      ]
    }
  ],
  "6_final_selected_patch": "diff --git a/sklearn/feature_extraction/text.py b/sklearn/feature_extraction/text.py\nindex d954f48..f6d64db 100644\n--- a/sklearn/feature_extraction/text.py\n+++ b/sklearn/feature_extraction/text.py\n@@ -130,10 +130,7 @@ def strip_accents_unicode(s):\n         ASCII equivalent.\n     \"\"\"\n     normalized = unicodedata.normalize('NFKD', s)\n-    if normalized == s:\n-        return s\n-    else:\n-        return ''.join([c for c in normalized if not unicodedata.combining(c)])\n+    return ''.join([c for c in normalized if not unicodedata.combining(c)])\n \n \n def strip_accents_ascii(s):\n",
  "7_resolved": true
}